cfa<- specifyModel()# Type these values that specify the model's relations (just use de Ctrl+R over each relation).
cov7 <- cov(sevenfmodel, y = NULL, use = "everything", method = c("pearson", "kendall", "spearman"))
summary(cfaSF36)
cfaSF36<- sem(cfa, cov7, N=542,standardized=FALSE)
summary(cfaSF36)
rm(list = ls())
ls()
#dettach all packages
detach()
#Instal packages needes for the analysis
lapply(c("sem", "ggplot2", "psych", "RCurl", "irr", "nortest", "moments","nFactors","psych","GPArotation"), library, character.only=T)
#####################################################################################
#IMPORTING DATA
#####################################################################################
#uploading data ------------------------------------------------------------------------
#Functions to pull the dara from the internet file
#see http://goo.gl/mQwxO on how to get this link
webdata <- getURL("https://docs.google.com/spreadsheet/pub?key=0AoTReYGK49h_dEl5UVYyMUpQcVZhSzZXWEQwaWIxUkE&single=true&gid=0&output=csv",ssl.verifypeer = FALSE)
SF361<-read.csv(textConnection(webdata))
SF36<-data.frame(na.exclude (SF361))
detach()
attach(SF36)
sevenmodel1<-names(SF36) %in% c("Q9","Q19_1")
sevenfmodel <- SF36[!sevenmodel1]
cfa<- specifyModel()# Type these values that specify the model's relations (just use de Ctrl+R over each relation).
str(SF36)
cfaSF36<- sem(cfa, cov7, N=557,standardized=FALSE)
cov7 <- cov(sevenfmodel, y = NULL, use = "everything", method = c("pearson", "kendall", "spearman"))
cfaSF36<- sem(cfa, cov7, N=557,standardized=FALSE)
cfa<- specifyModel()# Type these values that specify the model's relations (just use de Ctrl+R over each relation).
cfaSF36<- sem(cfa, cov7, N=557,standardized=FALSE)
summary(cfaSF36)
rm(list = ls())
ls()
#dettach all packages
detach()
#Instal packages needes for the analysis
lapply(c("sem", "ggplot2", "psych", "RCurl", "irr", "nortest", "moments","nFactors","psych","GPArotation"), library, character.only=T)
#####################################################################################
#IMPORTING DATA
#####################################################################################
#uploading data ------------------------------------------------------------------------
#Functions to pull the dara from the internet file
#see http://goo.gl/mQwxO on how to get this link
webdata <- getURL("https://docs.google.com/spreadsheet/pub?key=0AoTReYGK49h_dEl5UVYyMUpQcVZhSzZXWEQwaWIxUkE&single=true&gid=1&output=csv",ssl.verifypeer = FALSE)
SF361<-read.csv(textConnection(webdata))
SF36<-data.frame(na.exclude (SF361))
detach()
attach(SF36)
sevenmodel1<-names(SF36) %in% c("Q9","Q19_1")
sevenfmodel <- SF36[!sevenmodel1]
cfa<- specifyModel()# Type these values that specify the model's relations (just use de Ctrl+R over each relation).
cov7 <- cov(sevenfmodel, y = NULL, use = "everything", method = c("pearson", "kendall", "spearman"))
cfaSF36<- sem(cfa, cov7, N=557,standardized=FALSE)
summary(cfaSF36)
access_token <- AAACEdEose0cBAE3UZAOBwKmuvd0AT0dohjZCXajAtljdGU0umIj1FIP0hgZB0737VLcsrUqrgO187ja9UsX4vcj3arhZAZCNTx6JiELWANZCnmsZAeAQiEh
access_token <- AAACEdEose0cBAE3UZAOBwKmuvd0AT0dohjZCXajAtljdGU0umIj1FIP0hgZB0737VLcsrUqrgO187ja9UsX4vcj3arhZAZCNTx6JiELWANZCnmsZAeAQiEh
access_token <- c(AAACEdEose0cBAE3UZAOBwKmuvd0AT0dohjZCXajAtljdGU0umIj1FIP0hgZB0737VLcsrUqrgO187ja9UsX4vcj3arhZAZCNTx6JiELWANZCnmsZAeAQiEh)
access_token <- c("AAACEdEose0cBAE3UZAOBwKmuvd0AT0dohjZCXajAtljdGU0umIj1FIP0hgZB0737VLcsrUqrgO187ja9UsX4vcj3arhZAZCNTx6JiELWANZCnmsZAeAQiEh")
fix(access_token)
require(RCurl)
require(rjson)
install.packages("rjson")
facebook <-  function( path = "me", access_token, options){
if( !missing(options) ){
options <- sprintf( "?%s", paste( names(options), "=", unlist(options), collapse = "&", sep = "" ) )
} else {
options <- ""
}
data <- getURL( sprintf( "https://graph.facebook.com/%s%s&access_token=%s", path, options, access_token ) )
fromJSON( data )
}
myposts <- list()
i <- 0
next.path <- "me/posts"
while(length(next.path)!=0) {
i<-i+1
myposts[[i]] <- facebook(path=next.path , access_token=access_token)
next.path <- sub("https://graph.facebook.com/", "", myposts[[i]]$paging$'next')
}
require(rjson)
while(length(next.path)!=0) {
i<-i+1
myposts[[i]] <- facebook(path=next.path , access_token=access_token)
next.path <- sub("https://graph.facebook.com/", "", myposts[[i]]$paging$'next')
}
myposts[[i]] <- NULL
parse.master <- function(x, f)
sapply(x$data, f)
parse.likes <- function(x) if(!is.null(x$likes$count)) x$likes$count else 0
mylikes <- unlist(sapply(myposts, parse.master, f=parse.likes))
parse.messages <- function(x) if(!is.null(x$message)) x$message else NA
mymessages <- unlist(sapply(myposts, parse.master, f=parse.messages))
fix(parse.messages)
mymessages[which.max(mylikes)]
mylikes
mymessages
ted <- list()
i<-0
next.path <- "29092950651/posts"
# download all TED posts
while(length(next.path)!=0) {
i<-i+1
ted[[i]] <- facebook( path=next.path , access_token=access_token)
next.path <- sub("https://graph.facebook.com/","",ted[[i]]$paging$'next')
}
ted[[i]] <- NULL
# parse just video links posted by TED
parse.count.ted <- function(x)
if (x$type=="link" & x$from$id=="29092950651") x$likes$count else NA
parse.link.ted <- function(x)
if (x$type=="link" & x$from$id=="29092950651") x$link else NA
ted.counts <- unlist(sapply(ted, parse.master, f=parse.count.ted))
ted.links <- unlist(sapply(ted, parse.master, f=parse.link.ted))
# see three most popular talks
ted.links[order(ted.counts,decreasing=TRUE)][1:3]
scrape the list of friends
friends <- facebook( path="me/friends" , access_token=access_token)
friends.id <- sapply(friends$data, function(x) x$id)
friends.name <- sapply(friends$data, function(x)  iconv(x$name,"UTF-8","ASCII//TRANSLIT"))
initials <- function(x) paste(substr(x,1,1), collapse="")
friends.initial <- sapply(strsplit(friends.name," "), initials)
N <- length(friends.id)
friendship.matrix <- matrix(0,N,N)
for (i in 1:N) {
tmp <- facebook( path=paste("me/mutualfriends", friends.id[i], sep="/") , access_token=access_token)
mutualfriends <- sapply(tmp$data, function(x) x$id)
friendship.matrix[i,friends.id %in% mutualfriends] <- 1
}
View(friendship.matrix)
View(friendship.matrix)
require(Rgraphviz)
install.packages("Rgraphviz")
install.packages("Rgraphviz")
install.packages("Rgraphviz")
install.packages("Rgraphviz")
install.packages("Rgraphviz")
install.packages("Rgraphviz")
install.packages("Rgraphviz")
install.packages("Rgraphviz")
install.packages("Rgraphviz")
install.packages("Rgraphviz")
source("http://bioconductor.org/biocLite.R")
BiocInstaller::useDevel()
biocLite("Rgraphviz")
options(RCurlOptions = list(capath = system.file("CurlSSL", "cacert.pem", package = "RCurl"), ssl.verifypeer = FALSE))
data <- getURL("https://docs.google.com/spreadsheet/pub?hl=en&hl=en&key=0AoTReYGK49h_dFhMN3FRMUpTb01qbTVJcU9SMGktNXc&single=true&gid=0&output=csv"
,ssl.verifypeer = FALSE)
test<-read.csv(textConnection(data))
attach(test)
olecranon_day1 <- c(rt1speccoltd1, rt1specschatd1) #Ana, please add the variables that constitute all raters for day one
olecranon_day30 <- c(rt1speccoltd30, rt1specschatd30)
ckappa(olecranon_day1)
install.packages("psy")
library(psy)
ckappa(olecranon_day1)
data(expsy)
ckappa(expsy[,c(12,14)]) # Cohenâ€™s kappa for binary diagnosis
head(expsy)
library(boot)
ckappa.boot <- function(data,x) {ckappa(data[x,])[[2]]}
res <- boot(expsy[,c(12,14)],ckappa.boot,1000)
quantile(res$t,c(0.025,0.975)) # two-sided bootstrapped confidence interval of kappa
olecranon_day1
names(test)
olecranon_day1 <- c(rt1speccoltd1, rt1specschatd1, rt1specmayd1, rt1specaod1, rt2speccoltd1, rt2specschatd1, rt2specmayd1, rt2specaod1, rt3speccoltd1, rt3specschatd1, rt3specmayd1, rt3specaod1, rt4speccoltd1, rt4specschatd1, rt4specmayd1, rt4specaod1) #Ana, please add the variables that constitute all raters for day one
olecranon_day1
olecranon_day1 <- c(rt1speccoltd1, rt1specschatd1, rt1specmayd1, rt1specaod1, rt2speccoltd1, rt2specschatd1, rt2specmayd1, rt2specaod1, rt3speccoltd1, rt3specschatd1, rt3specmayd1, rt3specaod1, rt4speccoltd1, rt4specschatd1, rt4specmayd1, rt4specaod1) #Ana, please add the variables that constitute all raters for day one
olecranon_day30 <- c(rt1speccoltd30, rt1specschatd30, rt1specmayd30, rt1specaod30, rt2speccoltd30, rt2specschatd30, rt2specmayd30, rt2specaod30, rt3speccoltd30, rt3specschatd30, rt3specmayd30, rt3specaod30, rt4speccoltd30, rt4specschatd30, rt4specmayd30, rt4specaod30)
ole<-data.frame(olecranon_day1,olecranon_day30)
ckappa(ole)
library(boot)
ckappa.boot <- function(data,x) {ckappa(data[x,])[[2]]}
res <- boot(ole,ckappa.boot,1000)
quantile(res$t,c(0.025,0.975)) # two-sided bootstrapped confidence interval of kappa
boot.ci(res,type="bca") # adjusted bootstrap percentile (BCa) confidence interval (better)
expsy
names(test)
olecranon_day1sp <- c(rt1speccoltd1, rt1specschatd1, rt1specmayd1, rt1specaod1, rt2speccoltd1, rt2specschatd1, rt2specmayd1, rt2specaod1, rt3speccoltd1, rt3specschatd1, rt3specmayd1, rt3specaod1, rt4speccoltd1, rt4specschatd1, rt4specmayd1, rt4specaod1) #Ana, please add the variables that constitute all raters for day one
olecranon_day30sp <- c(rt1speccoltd30, rt1specschatd30, rt1specmayd30, rt1specaod30, rt2speccoltd30, rt2specschatd30, rt2specmayd30, rt2specaod30, rt3speccoltd30, rt3specschatd30, rt3specmayd30, rt3specaod30, rt4speccoltd30, rt4specschatd30, rt4specmayd30, rt4specaod30)
olecranon_day1nsp <- c(rt1nonspeccoltd1, rt1nonspecschatd1, rt1nonspecmayd1, rt1nonspecaod1,
rt2nonspeccoltd1, rt2nonspecschatd1, rt2nonspecmayd1, rt2nonspecaod1,
rt3nonspeccoltd1,
rt3nonspecschatd1, rt3nonspecmayd1, rt3nonspecaod1, rt4nonspeccoltd1,
rt4nonspecschatd1,
rt4nonspecmayd1, rt4nonspecaod1) #Ana, please add the variables that constitute all raters for day one
olecranon_day30nsp <- c(rt1nonspeccoltd30, rt1nonspecschatd30, rt1nonspecmayd30, rt1nonspecaod30,
rt2nonspeccoltd30, rt2nonspecschatd30, rt2nonspecmayd30, rt2nonspecaod30,
rt3nonspeccoltd30,
rt3nonspecschatd30, rt3nonspecmayd30, rt3nonspecaod30,
rt4nonspeccoltd30, rt4nonspecschatd30,
rt4nonspecmayd30, rt4nonspecaod30)
olesp<-data.frame(olecranon_day1sp,olecranon_day30sp)
olensp<-data.frame(olecranon_day1nsp,olecranon_day30nsp)
ckappa(olesp)
ckappa(olensp)
library(boot)
ckappa.boot <- function(data,x) {ckappa(data[x,])[[2]]}
res <- boot(olesp,ckappa.boot,1000)
icsp <- boot(olesp,ckappa.boot,1000)
quantile(icsp$t,c(0.025,0.975)) # two-sided bootstrapped confidence interval of kappa
boot.ci(icsp,type="bca") # adjusted bootstrap percentile (BCa) confidence interval (better)
icnsp <- boot(olensp,ckappa.boot,1000)
boot.ci(icnsp,type="bca") # adjusted bootstrap percentile (BCa) confidence interval (better)
olecranon.data <- read.csv("/Users/usuario/Google Drive/IOT/Cesar Guilherme/OlecranonFracture/OlecranonFracture.csv", header=T)
bland_altman_plot <- function(x,y,xlab="Average testresult", ylab="Deviation of experimental test")
{
x <- olecranon_day1sp  #var1, Ana here you should place the first observation to be compared
y <- olecranon_day30sp #var2, Ana here you should place the second observation to be compared
d <- ((olecranon_day1sp + olecranon_day30sp)/2) # Here the functino is calculating the avareg value of the paired observations, so just change the formule according to this sequence (1o observation + 2o Observation)
diff <- x - y  # This is calculating the difference between paired observations
#The plot command will give you the blanaltamn plot.
#The "ylim" cammand sets the limit for y axis, here is set to -6 to 6, but you can change if you want to ge a broader range.
#The "xlim"  command sets the limit for x axis.
plot(diff ~ d,pch=16,ylim=c(-6,6),xlim=c(1,6),xlab=xlab,ylab=ylab)
abline(h=mean(diff)-c(-1,0,1)*sd(diff),lty=2)
# The abline command will define the range for the agreement interval. Here it is set to 1 Standard Deviation + and 1 -, but you can change the range. See for genral information http://goo.gl/sv4kd and here http://goo.gl/IUbSJ for theoretical information about the plot.
}
bland_altman_plot(d,diff,xlab="Avarage",ylab="Difference Day1 to Day30")
summary(olecranon_day1sp)
head(olecranon_day1sp)
summary(test)
summary(olecranon_day30nsp)
olecranon_day30nsp
rt1nonspeccoltd30
summary(test)
olecranon_day1sp <- c(rt1speccoltd1, rt1specschatd1, rt1specmayd1, rt1specaod1, rt2speccoltd1, rt2specschatd1, rt2specmayd1, rt2specaod1, rt3speccoltd1, rt3specschatd1, rt3specmayd1, rt3specaod1, rt4speccoltd1, rt4specschatd1, rt4specmayd1, rt4specaod1) #Ana, please add the variables that constitute all raters for day one
olecranon_day1sp
rt1speccoltd1
require(Rgraphviz)
g <- new("graphAM", adjMat=friendship.matrix)
#scrape the list of friends
friends <- facebook( path="me/friends" , access_token=access_token)
# extract Facebook IDs
friends.id <- sapply(friends$data, function(x) x$id)
# extract names
friends.name <- sapply(friends$data, function(x)  iconv(x$name,"UTF-8","ASCII//TRANSLIT"))
# short names to initials
initials <- function(x) paste(substr(x,1,1), collapse="")
friends.initial <- sapply(strsplit(friends.name," "), initials)
# friendship relation matrix
N <- length(friends.id)
friendship.matrix <- matrix(0,N,N)
for (i in 1:N) {
tmp <- facebook( path=paste("me/mutualfriends", friends.id[i], sep="/") , access_token=access_token)
mutualfriends <- sapply(tmp$data, function(x) x$id)
friendship.matrix[i,friends.id %in% mutualfriends] <- 1
}
initials <- function(x) paste(substr(x,1,1), collapse="")
friends.initial <- sapply(strsplit(friends.name," "), initials)
# go to 'https://developers.facebook.com/tools/explorer' to get your access token
access_token <- c("AAACEdEose0cBAE3UZAOBwKmuvd0AT0dohjZCXajAtljdGU0umIj1FIP0hgZB0737VLcsrUqrgO187ja9UsX4vcj3arhZAZCNTx6JiELWANZCnmsZAeAQiEh")
require(RCurl)
require(rjson)
# Facebook json function copied from original (Romain Francois) post
facebook <-  function( path = "me", access_token, options){
if( !missing(options) ){
options <- sprintf( "?%s", paste( names(options), "=", unlist(options), collapse = "&", sep = "" ) )
} else {
options <- ""
}
data <- getURL( sprintf( "https://graph.facebook.com/%s%s&access_token=%s", path, options, access_token ) )
fromJSON( data )
}
#scrape the list of friends
friends <- facebook( path="me/friends" , access_token=access_token)
# extract Facebook IDs
friends.id <- sapply(friends$data, function(x) x$id)
# extract names
friends.name <- sapply(friends$data, function(x)  iconv(x$name,"UTF-8","ASCII//TRANSLIT"))
# short names to initials
initials <- function(x) paste(substr(x,1,1), collapse="")
friends.initial <- sapply(strsplit(friends.name," "), initials)
# friendship relation matrix
N <- length(friends.id)
friendship.matrix <- matrix(0,N,N)
for (i in 1:N) {
tmp <- facebook( path=paste("me/mutualfriends", friends.id[i], sep="/") , access_token=access_token)
mutualfriends <- sapply(tmp$data, function(x) x$id)
friendship.matrix[i,friends.id %in% mutualfriends] <- 1
}
View(friendship.matrix)
facebook <-  function( path = "me", access_token, options){
if( !missing(options) ){
options <- sprintf( "?%s", paste( names(options), "=", unlist(options), collapse = "&", sep = "" ) )
} else {
options <- ""
}
data <- getURL( sprintf( "https://graph.facebook.com/%s%s&access_token=%s", path, options, access_token ) )
fromJSON( data )
}
myposts <- list()
i <- 0
next.path <- "me/posts"
# download all my posts
while(length(next.path)!=0) {
i<-i+1
myposts[[i]] <- facebook(path=next.path , access_token=access_token)
next.path <- sub("https://graph.facebook.com/", "", myposts[[i]]$paging$'next')
}
myposts[[i]] <- NULL
parse.master <- function(x, f)
sapply(x$data, f)
parse.likes <- function(x) if(!is.null(x$likes$count)) x$likes$count else 0
mylikes <- unlist(sapply(myposts, parse.master, f=parse.likes))
parse.messages <- function(x) if(!is.null(x$message)) x$message else NA
mymessages <- unlist(sapply(myposts, parse.master, f=parse.messages))
# and the most liked status is...
mymessages[which.max(mylikes)]
access_token <- c("AAACEdEose0cBALLlYaHHcnW3C8WQKvI0Iom88ukPcZAix2ARhHsgfNbZCnkXnqt4RoUXxqqySjTSpndExKU4th9wvADFV34KwueDmLsuhYJAZA17ZCu7")
require(RCurl)
require(rjson)
facebook <-  function( path = "me", access_token, options){
if( !missing(options) ){
options <- sprintf( "?%s", paste( names(options), "=", unlist(options), collapse = "&", sep = "" ) )
} else {
options <- ""
}
data <- getURL( sprintf( "https://graph.facebook.com/%s%s&access_token=%s", path, options, access_token ) )
fromJSON( data )
}
myposts <- list()
i <- 0
next.path <- "me/posts"
# download all my posts
while(length(next.path)!=0) {
i<-i+1
myposts[[i]] <- facebook(path=next.path , access_token=access_token)
next.path <- sub("https://graph.facebook.com/", "", myposts[[i]]$paging$'next')
}
myposts[[i]] <- NULL
friends <- facebook( path="me/friends" , access_token=access_token)
friends.id <- sapply(friends$data, function(x) x$id)
friends.name <- sapply(friends$data, function(x)  iconv(x$name,"UTF-8","ASCII//TRANSLIT"))
initials <- function(x) paste(substr(x,1,1), collapse="")
friends.initial <- sapply(strsplit(friends.name," "), initials)
N <- length(friends.id)
friendship.matrix <- matrix(0,N,N)
for (i in 1:N) {
tmp <- facebook( path=paste("me/mutualfriends", friends.id[i], sep="/") , access_token=access_token)
mutualfriends <- sapply(tmp$data, function(x) x$id)
friendship.matrix[i,friends.id %in% mutualfriends] <- 1
}
N <- length(friends.id)
friendship.matrix <- matrix(0,N,N)
for (i in 1:N) {
tmp <- facebook( path=paste("me/mutualfriends", friends.id[i], sep="/") , access_token=access_token)
mutualfriends <- sapply(tmp$data, function(x) x$id)
friendship.matrix[i,friends.id %in% mutualfriends] <- 1
}
source("http://bioconductor.org/biocLite.R")
biocLite("Rgraphviz")
require(Rgraphviz)
g <- new("graphAM", adjMat=friendship.matrix)
g <- new("graphAM", adjMat=friendship.matrix, edgemode="directed")
g
pdf(file="facebook1.pdf", width=25, height=25)
attrs <- list(node=list(shape="ellipse", fixedsize=FALSE))
nAttrs <- list(label=friends.initial)
names(nAttrs$label) <- nodes(g)
plot(g, "neato", attrs=attrs, nodeAttrs=nAttrs)
View(friendship.matrix)
rm(list = ls())
ls()
#dettach all packages
detach()
#command below will install each package. if you run this script from the beginning you need to run every single one again
library("ggplot2")
library("car")
library("psych")
library("gmodels")
library(Hmisc)
library(VIM)
library(vmv)
#####################################################################################
#IMPORTING DATA AND RECODING
#####################################################################################
#if you are using a file that is local to your computer, then replace path below by path to the data file. command will throw all the data into the templateData object. replace the word template.data by a name that might easier for you to remember and that represents your data
#BaseVelber <- read.csv("~/Google Drive/RoR Duke/Analises R/MINE/BaseVelber.csv")
hpv <- read.csv("~/Google Drive/RoR Duke/HPV Open Collection/hpv.csv")
#below will view data in a spreadsheet format. notice that in this all subsequent commands you have to replace pref with whatever name you chose for your data object in the previous command
#View(pref)
#below will list variable names, classes (integer, factor, etc), alternative responses
str()
#list variable names so that they can be used later
names(hpv)
#below will attach your data so that when you execute a command you don't have to write the name of your data object over and over again
attach(hpv)
hpvnum<-data.frame(Age, Agemenarche, age1sex, numbersexpartners, parity,
agefirstbirth)
hpvcat<-data.frame(spontabortion,inducedabortion,pragnancy,oralsex,analsex,oralcont,STDpres,
smoke,alcohol)
Crosstab1<-data.frame(oralsex,analsex)
#function below is used to recode variables. things to notice: replace old.var with the variable you are recoding, replace new.var with the variable you want to create. the whole recoding happens within " ". all character and factor variables will be within '', numbers will be displayed with digits (not inside '') or NA (also without ''). see video at http://goo.gl/aDgo4 for more details
#new.var  <- car::recode(old.var, " 1:2 = 'A'; 3 = 'C'; '' = NA; else = 'B' ")
#new.Mturk <-as.factor(car::recode(Mturk, "1 = 'yes'; NA = 'no'"))
#tabulate(new.Mturk)
#pref$new.Age <- pref$Age
#class(pref$Age)
#new.Age <-as.factor(car::recode(Age,  "2:4 = '18 to 44'; 5:6 = '45 to 64'; 7:9 = '65 and over'"))
#tabulate(new.Age)
###########################################################################################
#Figures 1. Data Quality
###########################################################################################
##DATA QUALITY PLOTS
size<-c(55)
hpv2<-merge(hpv,size)
test <- qcc.groups(Agemenarche, Samples)
test <- qcc.groups(Agemenarche, Samples)
install.packages("VIM")
install.package("Hmisc","ggplot2")
install.packages
?install.packages
install.packages(c("Hmisc","ggplot2"))
install.packages(c("Hmisc","ggplot2","VIM","car","psych","gmodels","vmv","qcc","GGally","gridExtra"
,"Rcmdr"))
hpv <- read.csv("~/Google Drive/RoR Duke/HPV Open Collection/hpv.csv")
View(hpv)
hpv <- read.csv("~/Google Drive/RoR Duke/HPV Open Collection/hpv.csv")
library(Hmisc)
library(ggplot2)
library(VIM)
library("car")
library("psych")
library("gmodels")
library(vmv)
library(qcc)
library(GGally)
library(gridExtra)
library(Rcmdr)
hpv <- read.csv("/Users/rpietro/Google Drive/R/nonpublicdata_publications/HPV/hpv.csv")
hpv <- read.csv("~/Google Drive/RoR Duke/HPV Open Collection/hpv.csv")
hpvjoao <- read.csv("~/Google Drive/RoR Duke/HPV Open Collection/hpv.csv")
label(hpv$IDADE) <- "age at the time of the first consultation"
hpv <- read.csv("~/Google Drive/RoR Duke/HPV Open Collection/hpv.csv")
label(hpv$IDADE) <- "age at the time of the first consultation"
label(hpv$MENARCA)  <- "age at the time of the first period"
describe(hpv, exclude.missing=FALSE)
tablemissing(hpv)
size<-c(55)
hpv2<-merge(hpv,size)
qcc <- qcc.groups(Agemenarche, Samples)
par(mfrow=c(2,2))
obj1 <- qcc(qcc[1:11,], type="xbar")
obj2 <- qcc(Agemenarche, sizes=hpv2$y, type="p")
oc.curves(obj1)
cusum <- cusum(qcc[1:11,], decision.interval = 4, se.shift = 1)
ewma <- ewma(qcc[1:11,], lambda=0.2, nsigmas=3)
obj1 <- qcc(qcc[1:11,], type="xbar")
obj2 <- qcc(Agemenarche, sizes=hpv2$y, type="p")
oc.curves(obj1)
cusum <- cusum(qcc[1:11,], decision.interval = 4, se.shift = 1)
ewma <- ewma(qcc[1:11,], lambda=0.2, nsigmas=3)
cusum <- cusum(qcc[1:11,], decision.interval = 4, se.shift = 1)
obj1 <- qcc(qcc[1:11,], type="xbar")
obj2 <- qcc(Agemenarche, sizes=hpv2$y, type="p")
obj1 <- qcc(qcc[1:11,], type="xbar")
obj2 <- qcc(Agemenarche, sizes=hpv2$y, type="p")
oc.curves(obj1)
cusum <- cusum(qcc[1:11,], decision.interval = 4, se.shift = 1)
ewma <- ewma(qcc[1:11,], lambda=0.2, nsigmas=3)
par(mfrow=c(1,2))
obj1 <- qcc(qcc[1:11,], type="xbar")
obj2 <- qcc(Agemenarche, sizes=hpv2$y, type="p")
age<-ggally_dotAndBox(hpv, aes(x = Age, y = polymerase, col=polymerase), boxPlot=TRUE,
outlier.colour="red") + theme(legend.position = "none") + ylab("Age") +
xlab("Polymerase")
age
menarche<-ggally_dotAndBox(hpv, aes(x = Agemenarche, y = polymerase, col=polymerase), boxPlot=TRUE,
outlier.colour="red") + theme(legend.position = "none") +
xlab("Polymerase") + ylab("Age of Menarche")
menarche
sex<-ggally_dotAndBox(hpv, aes(x = age1sex, y = polymerase, col=polymerase), boxPlot=TRUE,
outlier.colour="red") + theme(legend.position = "none")+
ylab("Age of First Sexual Intercourse")
sex
partners<-ggally_dotAndBox(hpv, aes(x = numbersexpartners, y = polymerase, col=polymerase), boxPlot=TRUE,
outlier.colour="red") + theme(legend.position = "none")+
ylab("Number of sexual partners")
partners
parity<-ggally_dotAndBox(hpv, aes(x = parity, y = polymerase, col=polymerase), boxPlot=TRUE,
outlier.colour="red") + theme(legend.position = "none")+
ylab("Parity")
parity
agefirstbirth<-ggally_dotAndBox(hpv, aes(x = agefirstbirth, y = polymerase, col=polymerase), boxPlot=TRUE,
outlier.colour="red") + theme(legend.position = "none")+
ylab("Age of first birth")
agefirstbirth
grid.arrange(age,menarche,sex,partners,parity,agefirstbirth)
source("MINE.r")
setwd("~/Google Drive/RoR Duke/Analises R/HPVOpenDataCollection")
source("MINE.r")
MINE("hpv.csv","all.pairs",0,5)
scatterplot(parity ~ Age | polymerase, data=hpv,
xlab="Age", ylab="Parity",
main="",
labels=row.names(hpv))
scatter3d(hpv$Age, hpv$agefirstbirth, hpv$age1sex)
?grid.arrange
?grid.layout
plot1<-qplot(numbersexpartners, age1sex, data=hpv) +
geom_smooth()
plot2<-qplot(agefirstbirth, parity, data=hpv) +
geom_smooth(se=FALSE)
grid.arrange(plot1,plot2,nrow=1,ncol=2)
?install.packages
age<-ggally_dotAndBox(hpv, aes(x = Age, y = polymerase, col=polymerase), boxPlot=TRUE,
outlier.colour="red") + theme(legend.position = "none") + ylab("Age") +
xlab("Polymerase")
age
obj1 <- qcc(qcc[1:11,], type="xbar")
obj2 <- qcc(Agemenarche, sizes=hpv2$y, type="p")
